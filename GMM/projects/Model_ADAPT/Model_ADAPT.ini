# INI: ADAPT-MAIN #
# all of the lines may be specified also on the command line - see help (option -h)
# note: the term 'prm' used in this help denotes a file with extracted feature vectors

in-file = SP1.prm            # -i: prm file(s) with feature vectors to be adapted, or
                             # MLF file; option can be specified several times
                             # Note: if MLF file - also the -S option has to be set
in-list = SP_DIR             # -I: directory/list with paths to feature vectors to be adapted;
                             # option can be specified several times.
model-file-mode = false      # a model is created for each file specified in 'in-list' and/or 
                             # 'in-file'; models are stored in the directory specified by option 
                             # 'outDir' and has the extension specified by option 'outExt'

# ---- CLASSES -- BEGIN ---- # (OPTIONAL)
in-classes = MLF_classes.txt # -S: file containing list of classes to be adapted,
                             # may be specified several times, 
                             # two modes are available: MLF mode | CLASS mode 
			     #
                             # . [MLF mode] -- one has to insert MLF file (option -i) with time labels, 
                             # specify data directory (not mandatory, option -I, e.g. -I dir/myDir), 
			     # which is added as a prefix to filenames present in the MLF, and set
                             # the extension of input files (mandatory, option -e); htk files do contain
			     # also the sample period, for other types of input file formats one has to
			     # specify the sample period manually (see option --sample-period below);
			     # i-th line syntax of the 'in-classes' input file: 
                             #       class_i_ID element_1 element_2 ... element_N 
			     # a model (with filename 'class_i_ID') is then created for each set of elements,
			     # e.g. if MLF contains time intervals of phonemes present in given prm files, then
			     # one can train two models: 'silence' and 'vocals',
			     # two lines have to be specified in the 'MLF_classes.txt':
			     #       silence _sil_ _lb_ _ns_
			     #       speech a e i o u A E I O U
			     #
                             # . [CLASS mode] -- input file 'in-classes' has to contain information on classes,
			     # i-th line syntax is the same as for MLF mode, however 'element_i' 
                             # denotes now a prm filename (without extension, extension specified through -e), 
			     # path to the prm can be given directly in the input class-file, e.g.: 
			     #       class_i_ID path1/path2/element_1 ... path3/path4/element_N
			     # or specified using option -I dir/myDir (otherwise options -I and -i have not to be given)
                             # in this mode one model (with filename 'class_i_ID') is trained from several files
			     #
			     # Note 1: the distinction between MLF and CLASS mode is made by specifying option -i;
			     # Note 2: option -I can be specified in both modes only once;
			     # Note 3: output models are stored in directory specified by option -D 
			     #         and have an extension specified by option -x
			     #
sample-period = 1            # (MLF input & SVES | RAW prm - see option '--data-T') set feature sample-period for SVES|RAW files 
                             # (not required for HTK files) in order to derive samples from time labels occurring in the MLF

# ---- CLASSES --- END ----- #

outExt = .gmm                # -x: extension of output GMMs if more than one output model is assumed
outDir = ./                  # -D: output directory where to store output GMMs if more than one 
                             # output model is assumed or model-file-mode is on                             
in-UBM = UBM/bg.gmm          # -u: path to UBM; if not specified (along with 'in-dir-UBM') the model 
                             # will be trained from scratch; if specified along with the option '--nummix', 
			     # this model will be used for the initialization and its Gaussians will be further 
			     # divided until specified number of Gaussians is reached
in-dir-UBM = UBMs            # -U: path to directory containing initial model(s) (UBMs) to be adapted,
                             # if 'model-file-mode' is switched on, for each specified prm file a model 
			     # with the same filename will be searched in 'in-dir-UBM' and used as the 
			     # UBM to be adapted (i.e. different UBM for each input file); 
			     # in the CLASS or MLF mode each model is used as initial model for one class; 
                             # basename of model(s) should be equal to 'class_i_ID' (given in the classes file (see option -S)) 
                             # or to the basename of the outfile specified by option -o;
                             # if option not given, option -u is assumed as UBM input (one UBM for all the classes)
			     # note: only one of the options 'in-UBM' or 'in-dir-UBM' can be specified at a time
inExt-gmm = .gmm             # -E: extension of models in the directory 'in-dir-UBM'
outFile = OUT_DIR/SP1.gmm    # -o: (not for CLASS or MLF) where to store the adapted model or transformation matrix
file-by-file = false         # -f: accumulate statistics file by file from HDD, do not store all the feature vectors in the memory
                             # see also option --prm-buffer
inExt = .*                   # -e: extension of input prm files if input list is a directory (default '.*',
                             # in CLASS | MLF mode the default is '.prm')
data-T = 0                   # load prm files in sves(0)/htk(1)/raw(2) format (default: 0 = SVES format)
load-txt = false             # -L: load UBM from a text file
save-txt = false             # -T: save adapted model into a text file
save-in-stat-form = false    # save adapted model in format intended for statistics;
                             # note that also the MLLR transformation matrix can be saved in this format,
                             # rows are stored as stats.mean and if mllr-Qval is true than stats.mixProb
                             # are the values of the MLLR criterion for each row of W, otherwise stats.mixProb=1
full-cov = false             # if a model trained from scratch should have full covariances
nummix = 0                   # -g: specify number of Gaussians when model is trained from scratch; can be specified 
                             # along with initial GMM given by the option --in-UBM or --in-dir-UBM in order to 
			     # split Gaussians of an existing model;
			     # value greater than 0 will result in training from scratch (overrides --type, see below)
dwnsmp = 1                   # (not for MLF input) set feature down-sample factor
verbosity = 0                # -v: verbose mode

# INI: ADAPT #
type = 2                     # -t: FROM-SCRATCH=0, MLLR=1, MAP=2, fMLLR=3, MLLR+MAP=4
                             # note: if FROM_SCRATCH also 'nummix' has to be specified
split-X = 0.0                # (FROM_SCRATCH) number from interval <0,1>; if > 0 then 
                             # 'split-X'*100 percents of available Gaussians will be split 
			     # at once in each iteration; weight of these Gaussians must 
			     # be greater than 'split-th' * max_gauss_weight
split-th = 0.0               # (FROM_SCRATCH) number from interval <0,1>; see 'split-X' for more details;
                             # note: split-th=1 is equal to split-X=0
robust = false		     # -R: (FROM-SCRATCH|MAP) robust estimation of full covariances of GMM
ll-Th = 0.0		     # (FROM_SCRATCH) if the difference of log-likelihoods of models 
                             # between two iterations is lower than the threshold, the estimation will 
			     # end; otherwise it will continue until the number of iterations reaches 
			     # number of specified Gaussians
min-var = 1e-6               # minimal allowed variance occurring in the model with diagonal covariances
SSE = false                  # accumulate statistics using SSE instructions (speed boost)
CUDA = false                 # accumulate statistics using GPU CUDA (speed boost)
GPU-id = -1		     # -G: if more GPUs are available, which one should be used (0 - (#available devices-1));
                             # for --GPU-id=-1 the computation will be distributed among all available GPUs

it-EM = 0                    # (MAP|FROM_SCRATCH) after each iteration UBM is replaced by the newly adapted 
                             # model => computation of statistics => adaptation => ...
it-MAP = 1                   # (MAP) statistic are computed from the last adapted model, 
                             # but UBM is used for weighing
mean = false                 # -M: (MAP) mixture mean will be adapted
var = false                  # -V: (MAP) mixture variance will be adapted
weight = false               # -W: (MAP) mixture weight will be adapted
tau = 14                     # -r: (MAP) relevance factor
del-mix = 0                  # if > 0 => mixtures with occupation < del-mix are discarded
del-mix-p = 50               # none of the mixtures is discarded if more than del-mix-p % 
                             # of mixtures should be discarded
mat-ext = .mat               # -X: output extension of file with transformation matrix
apply-trn = false            # -a: (MLLR) after adaptation MLLR matrix is used to transform the model
save-trn = false             # -s: (MLLR) save transformation matrices
mllr-init = true             # (MLLR) MLLR will be initialized with statistics extracted from UBM 
                             # to increase the robustness of the estimation (useful mainly when only 
                             # a few data are available)
mllr-Qval = false            # (MLLR) values of the MLLR criterion for each row of W will be computed;
                             # they will be saved when save-in-stat-form is true => they are stored
                             # as stats.mixProbs                          
it-mllr = 1                  # (MLLR) number of MLLR iterations

NB-GPU = 8                   # number of accumulators on GPU - summed at the end; 
                             # usefull (speed up) for lower amount of Gaussians (~32)
prm-buffer-gpu = 0.0         # maximum size of memory used on GPU, if 0 then it will be determined automatically
                             # according to the available space on the GPU
numThrd = 1                  # number of CPUs used
prm-buffer = 0.005           # maximum size of a buffer used to load the feature vectors given
                             # in giga-bytes; takes effect only if file-by-file = true

tmp-N = 0                    # (FROM_SCRATCH) save a temporary model after each 'tmp-N'-splits
